head	2.2;
access;
symbols
	cvs-200501061500:1.1.5.1
	TNF:1.1.5
	start:1.1.1.1
	openbsd:1.1.1;
locks; strict;
comment	@ * @;


2.2
date	2005.01.09.15.02.36;	author tg;	state Exp;
branches;
next	2.1;

2.1
date	2005.01.03.16.37.24;	author tg;	state Exp;
branches;
next	1.1;

1.1
date	2004.12.12.21.33.29;	author tg;	state Exp;
branches
	1.1.1.1
	1.1.5.1;
next	;

1.1.1.1
date	2004.12.12.21.33.29;	author tg;	state Exp;
branches;
next	;

1.1.5.1
date	2005.01.06.20.13.38;	author tg;	state Exp;
branches;
next	;


desc
@@


2.2
log
@unfold the kernel part of ocvs:mergefixes into the new master tree,
effectively switching src/ over
@
text
@/**	$MirBSD: src/sys/kern/kern_timeout.c,v 1.10.8.1 2005/01/09 14:28:05 tg Exp $ */
/*	$NetBSD: kern_timeout.c,v 1.13 2003/10/30 04:32:56 thorpej Exp $	*/
/*	$OpenBSD: kern_timeout.c,v 1.18 2003/06/03 12:05:25 art Exp $	*/

/*-
 * Copyright (c) 2003 The NetBSD Foundation, Inc.
 * All rights reserved.
 *
 * This code is derived from software contributed to The NetBSD Foundation
 * by Jason R. Thorpe.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the NetBSD
 *	Foundation, Inc. and its contributors.
 * 4. Neither the name of The NetBSD Foundation nor the names of its
 *    contributors may be used to endorse or promote products derived
 *    from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE NETBSD FOUNDATION, INC. AND CONTRIBUTORS
 * ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE FOUNDATION OR CONTRIBUTORS
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 */

/*
 * Copyright (c) 2003, 2005 Thorsten Glaser <tg@@66h.42h.de>
 * Copyright (c) 2001 Thomas Nordin <nordin@@openbsd.org>
 * Copyright (c) 2000-2001 Artur Grabowski <art@@openbsd.org>
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 *
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. The name of the author may not be used to endorse or promote products
 *    derived from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES,
 * INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY
 * AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL
 * THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 * EXEMPLARY, OR CONSEQUENTIAL  DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
 * OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
 * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
 * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/kernel.h>
#include <sys/lock.h>
#include <sys/timeout.h>

#ifdef DDB
#include <machine/db_machdep.h>
#include <ddb/db_interface.h>
#include <ddb/db_access.h>
#include <ddb/db_sym.h>
#include <ddb/db_output.h>
#endif

/*
 * Timeouts are kept in a hierarchical timing wheel. The to_time is the value
 * of the global variable "ticks" when the timeout should be called.
 * There are four levels with 256 buckets each. See 'Scheme 7' in
 * "Hashed and Hierarchical Timing Wheels: Efficient Data Structures for
 * Implementing a Timer Facility" by George Varghese and Tony Lauck.
 */
#define BUCKETS 1024
#define WHEELSIZE 256
#define WHEELMASK 255
#define WHEELBITS 8

static struct timeout_circq timeout_wheel[BUCKETS];	/* Queues of timeouts */
static struct timeout_circq timeout_todo;		/* Worklist */

#define MASKWHEEL(wheel, time) (((time) >> ((wheel)*WHEELBITS)) & WHEELMASK)

#define BUCKET(rel, abs)						\
    (((rel) <= (1 << (2*WHEELBITS)))					\
    	? ((rel) <= (1 << WHEELBITS))					\
            ? &timeout_wheel[MASKWHEEL(0, (abs))]			\
            : &timeout_wheel[MASKWHEEL(1, (abs)) + WHEELSIZE]		\
        : ((rel) <= (1 << (3*WHEELBITS)))				\
            ? &timeout_wheel[MASKWHEEL(2, (abs)) + 2*WHEELSIZE]		\
            : &timeout_wheel[MASKWHEEL(3, (abs)) + 3*WHEELSIZE])

#define MOVEBUCKET(wheel, time)						\
    CIRCQ_APPEND(&timeout_todo,						\
        &timeout_wheel[MASKWHEEL((wheel), (time)) + (wheel)*WHEELSIZE])

/*
 * All wheels are locked with the same lock (which must also block out all
 * interrupts).
 */
static struct simplelock callout_slock;

#define	CALLOUT_LOCK(s)							\
do {									\
	s = splhigh();							\
	simple_lock(&callout_slock);					\
} while (/*CONSTCOND*/0)

#define	CALLOUT_UNLOCK(s)						\
do {									\
	simple_unlock(&callout_slock);					\
	splx((s));							\
} while (/*CONSTCOND*/0)

/*
 * Circular queue definitions.
 */

#define CIRCQ_INIT(list)						\
do {									\
        (list)->next_l = (list);			\
        (list)->prev_l = (list);			\
} while (/*CONSTCOND*/0)

#define CIRCQ_INSERT(elem, list)					\
do {									\
        (elem)->prev_e = (list)->prev_e;		\
        (elem)->next_l = (list);			\
        (list)->prev_l->next_l = (elem);		\
        (list)->prev_l = (elem);			\
} while (/*CONSTCOND*/0)

#define CIRCQ_APPEND(fst, snd)						\
do {									\
        if (!CIRCQ_EMPTY(snd)) {			\
                (fst)->prev_l->next_l = (snd)->next_l;	\
                (snd)->next_l->prev_l = (fst)->prev_l;	\
                (snd)->prev_l->next_l = (fst);		\
                (fst)->prev_l = (snd)->prev_l;		\
                CIRCQ_INIT(snd);			\
        }						\
} while (/*CONSTCOND*/0)

#define CIRCQ_REMOVE(elem)						\
do {									\
        (elem)->next_l->prev_e = (elem)->prev_e;	\
        (elem)->prev_l->next_e = (elem)->next_e;	\
} while (/*CONSTCOND*/0)

#define	CIRCQ_FIRST(list)	((list)->next_e)
#define	CIRCQ_NEXT(elem)	((elem)->next_e)
#define	CIRCQ_LAST(elem,list)	((elem)->next_l == (list))
#define	CIRCQ_EMPTY(list)	((list)->next_l == (list))

/*
 * Some of the "math" in here is a bit tricky.
 *
 * We have to beware of wrapping ints.
 * We use the fact that any element added to the queue must be added with a
 * positive time. That means that any element `to' on the queue cannot be
 * scheduled to timeout further in time than INT_MAX, but c->to_time can
 * be positive or negative so comparing it with anything is dangerous.
 * The only way we can use the c->to_time value in any predictable way
 * is when we calculate how far in the future `to' will timeout -
 * "c->to_time - ticks". The result will always be positive for
 * future timeouts and 0 or negative for due timeouts.
 */
extern int ticks;		/* XXX - move to sys/X.h */

void
timeout_startup(void)
{
	int b;

	CIRCQ_INIT(&timeout_todo);
	for (b = 0; b < BUCKETS; b++)
		CIRCQ_INIT(&timeout_wheel[b]);
	simple_lock_init(&callout_slock);
}

void
timeout_set(struct timeout *new, void (*fn)(void *), void *arg)
{
	new->to_time = 0;
	new->to_func = fn;
	new->to_arg = arg;
	new->to_flags = TIMEOUT_INITIALIZED;
}

void
timeout_add(struct timeout *c, int to_ticks)
{
	int s, old_time;

#ifdef DIAGNOSTIC
	if (!(c->to_flags & TIMEOUT_INITIALIZED))
		panic("timeout_add: not initialized");
	if (to_ticks < 0)
		panic("timeout_add: to_ticks < 0");
#endif

	CALLOUT_LOCK(s);

	/* Initialize the time here, it won't change. */
	old_time = c->to_time;
	c->to_time = to_ticks + ticks;
	c->to_flags &= ~TIMEOUT_TRIGGERED;

	/*
	 * If this timeout is already scheduled and now is moved
	 * earlier, reschedule it now. Otherwise leave it in place
	 * and let it be rescheduled later.
	 */
	if (c->to_flags & TIMEOUT_ONQUEUE) {
		if (c->to_time - old_time < 0) {
			CIRCQ_REMOVE(&c->to_list);
			CIRCQ_INSERT(&c->to_list, &timeout_todo);
		}
	} else {
		c->to_flags |= TIMEOUT_ONQUEUE;
		CIRCQ_INSERT(&c->to_list, &timeout_todo);
	}

	CALLOUT_UNLOCK(s);
}

void
timeout_del(struct timeout *c)
{
	int s;

	CALLOUT_LOCK(s);

	if (c->to_flags & TIMEOUT_ONQUEUE) {
		CIRCQ_REMOVE(&c->to_list);
		c->to_flags &= ~TIMEOUT_ONQUEUE;
	}

	c->to_flags &= ~TIMEOUT_TRIGGERED;

	CALLOUT_UNLOCK(s);
}

/*
 * This is called from hardclock() once every tick.
 * We return !0 if we need to schedule a softclock.
 *
 * We don't need locking in here.
 */
int
timeout_hardclock_update(void)
{
	MOVEBUCKET(0, ticks);
	if (MASKWHEEL(0, ticks) == 0) {
		MOVEBUCKET(1, ticks);
		if (MASKWHEEL(1, ticks) == 0) {
			MOVEBUCKET(2, ticks);
			if (MASKWHEEL(2, ticks) == 0)
				MOVEBUCKET(3, ticks);
		}
	}

	return !CIRCQ_EMPTY(&timeout_todo);
}

/* ARGSUSED */
void
softclock(void)
{
	struct timeout *c;
	void (*func)(void *);
	void *arg;
	int s;

	CALLOUT_LOCK(s);

	while (!CIRCQ_EMPTY(&timeout_todo)) {
		c = CIRCQ_FIRST(&timeout_todo);
		CIRCQ_REMOVE(&c->to_list);

		/* If due run it, otherwise insert it into the right bucket. */
		if (c->to_time - ticks > 0) {
			CIRCQ_INSERT(&c->to_list,
			    BUCKET((c->to_time - ticks), c->to_time));
		} else {
#ifdef DEBUG
			if (c->to_time - ticks < 0)
				printf("timeout delayed %d\n", c->to_time -
				    ticks);
#endif
			c->to_flags &= ~TIMEOUT_ONQUEUE;
			c->to_flags |= TIMEOUT_TRIGGERED;

			func = c->to_func;
			arg = c->to_arg;

			CALLOUT_UNLOCK(s);
			(*func)(arg);
			CALLOUT_LOCK(s);
		}
	}

	CALLOUT_UNLOCK(s);
}

#ifdef DDB
static void db_show_callout_bucket(struct timeout_circq *);

static void
db_show_callout_bucket(struct timeout_circq *bucket)
{
	struct timeout *c;
	db_expr_t offset;
	char *name;

	if (CIRCQ_EMPTY(bucket))
		return;

	for (c = CIRCQ_FIRST(bucket); /*nothing*/; c = CIRCQ_NEXT(&c->to_list)) {
		db_find_sym_and_offset((db_addr_t)(intptr_t)c->to_func, &name,
		    &offset);
		name = name ? name : "?";
#ifdef _LP64
#define	POINTER_WIDTH	"%16lX"
#else
#define	POINTER_WIDTH	"%8lX"
#endif
		db_printf("%9d %2d/%-4d " POINTER_WIDTH "  %s\n",
		    c->to_time - ticks,
		    (int)((bucket - timeout_wheel) / WHEELSIZE),
		    (int)(bucket - timeout_wheel), (u_long) c->to_arg, name);

		if (CIRCQ_LAST(&c->to_list, bucket))
			break;
	}
}

void
db_show_callout(db_expr_t addr, int haddr, db_expr_t count, char *modif)
{
	int b;

	db_printf("ticks now: %d\n", ticks);
#ifdef _LP64
	db_printf("    ticks  wheel       arg  func\n");
#else
	db_printf("    ticks  wheel       arg  func\n");
#endif

	/*
	 * Don't lock the callwheel; all the other CPUs are paused
	 * anyhow, and we might be called in a circumstance where
	 * some other CPU was paused while holding the lock.
	 */

	db_show_callout_bucket(&timeout_todo);
	for (b = 0; b < BUCKETS; b++)
		db_show_callout_bucket(&timeout_wheel[b]);
}
#endif /* DDB */
@


2.1
log
@work over most of the changes MirOS has done, and add
the new or copied/moved files
@
text
@d1 2
a2 1
/*	$MirBSD: src/sys/kern/kern_timeout.c,v 1.10 2004/07/01 21:53:06 tg Stab $	*/
d4 37
a40 1
/*	$NetBSD: kern_timeout.c,v 1.11 2003/09/25 10:44:11 scw Exp $	*/
d42 1
d53 4
a56 1
 * 2. The name of the author may not be used to endorse or promote products
d59 1
a59 1
 * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
d73 1
d87 2
a88 2
 * of the global variable "ticks" when the timeout should be called. There are
 * four levels with 256 buckets each. See 'Scheme 7' in
d97 2
a98 2
struct timeout_circq timeout_wheel[BUCKETS];	/* Queues of timeouts */
struct timeout_circq timeout_todo;		/* Worklist */
d105 2
a106 2
            ? timeout_wheel[MASKWHEEL(0, (abs))]			\
            : timeout_wheel[MASKWHEEL(1, (abs)) + WHEELSIZE]		\
d108 2
a109 2
            ? timeout_wheel[MASKWHEEL(2, (abs)) + 2*WHEELSIZE]		\
            : timeout_wheel[MASKWHEEL(3, (abs)) + 3*WHEELSIZE])
d119 1
a119 1
struct simplelock _timeout_lock;
d121 11
a131 4
#define timeout_wheel_lock(s) \
	do { *(s) = splhigh(); simple_lock(&_timeout_lock); } while (0)
#define timeout_wheel_unlock(s) \
	do { simple_unlock(&_timeout_lock); splx(s); } while (0)
d137 2
a138 1
#define CIRCQ_INIT(list) do {				\
d141 1
a141 1
} while (0)
d143 2
a144 1
#define CIRCQ_INSERT(elem, list) do {			\
d149 1
a149 1
} while (0)
d151 2
a152 1
#define CIRCQ_APPEND(fst, snd) do {			\
d160 1
a160 1
} while (0)
d162 2
a163 1
#define CIRCQ_REMOVE(elem) do {				\
d166 1
a166 1
} while (0)
d178 2
a179 2
 * positive time. That means that any element 'to' on the queue cannot be
 * scheduled to timeout further in time than INT_MAX, but to->to_time can
d181 4
a184 4
 * The only way we can use the to->to_time value in any predictable way
 * is when we calculate how far in the future 'to' will timeout -
 * "to->to_time - ticks". The result will always be positive for future
 * timeouts and 0 or negative for due timeouts.
d196 1
a196 1
	simple_lock_init(&_timeout_lock);
a207 1

d209 1
a209 1
timeout_add(struct timeout *new, int to_ticks)
d211 1
a211 2
	int s;
	int old_time;
d214 1
a214 1
	if (!(new->to_flags & TIMEOUT_INITIALIZED))
d220 2
a221 1
	timeout_wheel_lock(&s);
d223 3
a225 3
	old_time = new->to_time;
	new->to_time = to_ticks + ticks;
	new->to_flags &= ~TIMEOUT_TRIGGERED;
d228 1
a228 1
	 * If this timeout already is scheduled and now is moved
d232 4
a235 4
	if (new->to_flags & TIMEOUT_ONQUEUE) {
		if (new->to_time - ticks < old_time - ticks) {
			CIRCQ_REMOVE(&new->to_list);
			CIRCQ_INSERT(&new->to_list, &timeout_todo);
d238 2
a239 2
		new->to_flags |= TIMEOUT_ONQUEUE;
		CIRCQ_INSERT(&new->to_list, &timeout_todo);
d242 1
a242 1
	timeout_wheel_unlock(s);
d246 1
a246 1
timeout_del(struct timeout *to)
d250 5
a254 4
	timeout_wheel_lock(&s);
	if (to->to_flags & TIMEOUT_ONQUEUE) {
		CIRCQ_REMOVE(&to->to_list);
		to->to_flags &= ~TIMEOUT_ONQUEUE;
d256 4
a259 2
	to->to_flags &= ~TIMEOUT_TRIGGERED;
	timeout_wheel_unlock(s);
d280 2
a281 1
	return (!CIRCQ_EMPTY(&timeout_todo));
d284 1
d288 3
a290 1
	struct timeout *to;
a291 2
	void (*fn)(void *);
	void *arg;
d293 2
a294 1
	timeout_wheel_lock(&s);
d296 2
a297 3

		to = CIRCQ_FIRST(&timeout_todo);
		CIRCQ_REMOVE(&to->to_list);
d300 3
a302 3
		if (to->to_time - ticks > 0) {
			CIRCQ_INSERT(&to->to_list,
			    &BUCKET((to->to_time - ticks), to->to_time));
d305 2
a306 2
			if (to->to_time - ticks < 0)
				printf("timeout delayed %d\n", to->to_time -
d309 2
a310 2
			to->to_flags &= ~TIMEOUT_ONQUEUE;
			to->to_flags |= TIMEOUT_TRIGGERED;
d312 2
a313 2
			fn = to->to_func;
			arg = to->to_arg;
d315 3
a317 3
			timeout_wheel_unlock(s);
			fn(arg);
			timeout_wheel_lock(&s);
d320 2
a321 1
	timeout_wheel_unlock(s);
d325 1
a325 1
void db_show_callout_bucket(struct timeout_circq *);
d327 1
a327 1
void
d330 1
a330 1
	struct timeout *to;
d337 3
a339 3
	for (to = CIRCQ_FIRST(bucket); /* nothing */;
	    to = CIRCQ_NEXT(&to->to_list)) {
		db_find_sym_and_offset((db_addr_t)to->to_func, &name, &offset);
d341 11
a351 4
		db_printf("%9d %2d/%-4d %8x  %s\n", to->to_time - ticks,
		    (bucket - timeout_wheel) / WHEELSIZE,
		    bucket - timeout_wheel, (unsigned)to->to_arg, name);
		if (CIRCQ_LAST(&to->to_list, bucket))
a358 1
	int s;
d362 1
d364 3
d368 5
a372 1
	timeout_wheel_lock(&s);
a376 2

	timeout_wheel_unlock(s);
d378 1
a378 1
#endif
@


1.1
log
@Initial revision
@
text
@d1 1
d3 1
d7 1
a7 1
 * All rights reserved. 
d9 3
a11 3
 * Redistribution and use in source and binary forms, with or without 
 * modification, are permitted provided that the following conditions 
 * are met: 
d13 2
a14 2
 * 1. Redistributions of source code must retain the above copyright 
 *    notice, this list of conditions and the following disclaimer. 
d16 1
a16 1
 *    derived from this software without specific prior written permission. 
d18 1
a18 1
 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES,
d27 1
a27 1
 * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
d55 2
a56 2
struct circq timeout_wheel[BUCKETS];	/* Queues of timeouts */
struct circq timeout_todo;		/* Worklist */
d88 3
a90 3
#define CIRCQ_INIT(elem) do {                   \
        (elem)->next = (elem);                  \
        (elem)->prev = (elem);                  \
d93 5
a97 5
#define CIRCQ_INSERT(elem, list) do {           \
        (elem)->prev = (list)->prev;            \
        (elem)->next = (list);                  \
        (list)->prev->next = (elem);            \
        (list)->prev = (elem);                  \
d100 8
a107 8
#define CIRCQ_APPEND(fst, snd) do {             \
        if (!CIRCQ_EMPTY(snd)) {                \
                (fst)->prev->next = (snd)->next;\
                (snd)->next->prev = (fst)->prev;\
                (snd)->prev->next = (fst);      \
                (fst)->prev = (snd)->prev;      \
                CIRCQ_INIT(snd);                \
        }                                       \
d110 3
a112 3
#define CIRCQ_REMOVE(elem) do {                 \
        (elem)->next->prev = (elem)->prev;      \
        (elem)->prev->next = (elem)->next;      \
d115 4
a118 3
#define CIRCQ_FIRST(elem) ((elem)->next)

#define CIRCQ_EMPTY(elem) (CIRCQ_FIRST(elem) == (elem))
d125 1
a125 1
 * positive time. That means that any element `to' on the queue cannot be
d129 1
a129 1
 * is when we calculate how far in the future `to' will timeout -
d149 1
d239 1
a239 1
		to = (struct timeout *)CIRCQ_FIRST(&timeout_todo); /* XXX */
d267 1
a267 1
void db_show_callout_bucket(struct circq *);
d270 1
a270 1
db_show_callout_bucket(struct circq *bucket)
a272 1
	struct circq *p;
d276 5
a280 2
	for (p = CIRCQ_FIRST(bucket); p != bucket; p = CIRCQ_FIRST(p)) {
		to = (struct timeout *)p; /* XXX */
d285 3
a287 1
		    bucket - timeout_wheel, to->to_arg, name);
@


1.1.5.1
log
@the very kern_timeout.c from NetBSD(tm) we base ours from
@
text
@d1 1
a1 38
/*	$NetBSD: kern_timeout.c,v 1.13 2003/10/30 04:32:56 thorpej Exp $	*/

/*-
 * Copyright (c) 2003 The NetBSD Foundation, Inc.
 * All rights reserved.
 *
 * This code is derived from software contributed to The NetBSD Foundation
 * by Jason R. Thorpe.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the NetBSD
 *	Foundation, Inc. and its contributors.
 * 4. Neither the name of The NetBSD Foundation nor the names of its
 *    contributors may be used to endorse or promote products derived
 *    from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE NETBSD FOUNDATION, INC. AND CONTRIBUTORS
 * ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE FOUNDATION OR CONTRIBUTORS
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 */

d13 1
a13 4
 * 2. Redistributions in binary form must reproduce the above copyright 
 *    notice, this list of conditions and the following disclaimer in the 
 *    documentation and/or other materials provided with the distribution. 
 * 3. The name of the author may not be used to endorse or promote products
a27 8
#include <sys/cdefs.h>
__KERNEL_RCSID(0, "$NetBSD: kern_timeout.c,v 1.13 2003/10/30 04:32:56 thorpej Exp $");

/*
 * Adapted from OpenBSD: kern_timeout.c,v 1.15 2002/12/08 04:21:07 art Exp,
 * modified to match NetBSD's pre-existing callout API.
 */

a29 1
#include <sys/kernel.h>
d31 1
a31 1
#include <sys/callout.h>
d42 3
a44 3
 * Timeouts are kept in a hierarchical timing wheel. The c_time is the value
 * of the global variable "hardclock_ticks" when the timeout should be called.
 * There are four levels with 256 buckets each. See 'Scheme 7' in
d53 2
a54 2
static struct callout_circq timeout_wheel[BUCKETS];	/* Queues of timeouts */
static struct callout_circq timeout_todo;		/* Worklist */
d61 2
a62 2
            ? &timeout_wheel[MASKWHEEL(0, (abs))]			\
            : &timeout_wheel[MASKWHEEL(1, (abs)) + WHEELSIZE]		\
d64 2
a65 2
            ? &timeout_wheel[MASKWHEEL(2, (abs)) + 2*WHEELSIZE]		\
            : &timeout_wheel[MASKWHEEL(3, (abs)) + 3*WHEELSIZE])
d75 1
a75 1
static struct simplelock callout_slock;
d77 4
a80 11
#define	CALLOUT_LOCK(s)							\
do {									\
	s = splsched();							\
	simple_lock(&callout_slock);					\
} while (/*CONSTCOND*/0)

#define	CALLOUT_UNLOCK(s)						\
do {									\
	simple_unlock(&callout_slock);					\
	splx((s));							\
} while (/*CONSTCOND*/0)
d86 30
a115 35
#define CIRCQ_INIT(list)						\
do {									\
        (list)->cq_next_l = (list);					\
        (list)->cq_prev_l = (list);					\
} while (/*CONSTCOND*/0)

#define CIRCQ_INSERT(elem, list)					\
do {									\
        (elem)->cq_prev_e = (list)->cq_prev_e;				\
        (elem)->cq_next_l = (list);					\
        (list)->cq_prev_l->cq_next_l = (elem);				\
        (list)->cq_prev_l = (elem);					\
} while (/*CONSTCOND*/0)

#define CIRCQ_APPEND(fst, snd)						\
do {									\
        if (!CIRCQ_EMPTY(snd)) {					\
                (fst)->cq_prev_l->cq_next_l = (snd)->cq_next_l;		\
                (snd)->cq_next_l->cq_prev_l = (fst)->cq_prev_l;		\
                (snd)->cq_prev_l->cq_next_l = (fst);			\
                (fst)->cq_prev_l = (snd)->cq_prev_l;			\
                CIRCQ_INIT(snd);					\
        }								\
} while (/*CONSTCOND*/0)

#define CIRCQ_REMOVE(elem)						\
do {									\
        (elem)->cq_next_l->cq_prev_e = (elem)->cq_prev_e;		\
        (elem)->cq_prev_l->cq_next_e = (elem)->cq_next_e;		\
} while (/*CONSTCOND*/0)

#define CIRCQ_FIRST(list)	((list)->cq_next_e)
#define CIRCQ_NEXT(elem)	((elem)->cq_next_e)
#define CIRCQ_LAST(elem,list)	((elem)->cq_next_l == (list))
#define CIRCQ_EMPTY(list)	((list)->cq_next_l == (list))
d123 1
a123 1
 * scheduled to timeout further in time than INT_MAX, but c->c_time can
d125 1
a125 1
 * The only way we can use the c->c_time value in any predictable way
d127 2
a128 2
 * "c->c_time - hardclock_ticks". The result will always be positive for
 * future timeouts and 0 or negative for due timeouts.
d130 1
a131 9
#ifdef CALLOUT_EVENT_COUNTERS
static struct evcnt callout_ev_late;
#endif

/*
 * callout_startup:
 *
 *	Initialize the callout facility, called at system startup time.
 */
d133 1
a133 1
callout_startup(void)
d140 1
a140 6
	simple_lock_init(&callout_slock);

#ifdef CALLOUT_EVENT_COUNTERS
	evcnt_attach_dynamic(&callout_ev_late, EVCNT_TYPE_MISC,
	    NULL, "callout", "late");
#endif
a142 5
/*
 * callout_init:
 *
 *	Initialize a callout structure.
 */
d144 1
a144 1
callout_init(struct callout *c)
d146 3
a148 2

	memset(c, 0, sizeof(*c));
a150 40
/*
 * callout_reset:
 *
 *	Reset a callout structure with a new function and argument, and
 *	schedule it to run.
 */
void
callout_reset(struct callout *c, int to_ticks, void (*func)(void *), void *arg)
{
	int s, old_time;

	KASSERT(to_ticks >= 0);

	CALLOUT_LOCK(s);

	/* Initialize the time here, it won't change. */
	old_time = c->c_time;
	c->c_time = to_ticks + hardclock_ticks;
	c->c_flags &= ~(CALLOUT_FIRED|CALLOUT_INVOKING);

	c->c_func = func;
	c->c_arg = arg;

	/*
	 * If this timeout is already scheduled and now is moved
	 * earlier, reschedule it now. Otherwise leave it in place
	 * and let it be rescheduled later.
	 */
	if (callout_pending(c)) {
		if (c->c_time - old_time < 0) {
			CIRCQ_REMOVE(&c->c_list);
			CIRCQ_INSERT(&c->c_list, &timeout_todo);
		}
	} else {
		c->c_flags |= CALLOUT_PENDING;
		CIRCQ_INSERT(&c->c_list, &timeout_todo);
	}

	CALLOUT_UNLOCK(s);
}
a151 6
/*
 * callout_schedule:
 *
 *	Schedule a callout to run.  The function and argument must
 *	already be set in the callout structure.
 */
d153 1
a153 1
callout_schedule(struct callout *c, int to_ticks)
d155 2
a156 1
	int s, old_time;
d158 6
a163 3
	KASSERT(to_ticks >= 0);

	CALLOUT_LOCK(s);
d165 1
d167 3
a169 3
	old_time = c->c_time;
	c->c_time = to_ticks + hardclock_ticks;
	c->c_flags &= ~(CALLOUT_FIRED|CALLOUT_INVOKING);
d172 1
a172 1
	 * If this timeout is already scheduled and now is moved
d176 4
a179 4
	if (callout_pending(c)) {
		if (c->c_time - old_time < 0) {
			CIRCQ_REMOVE(&c->c_list);
			CIRCQ_INSERT(&c->c_list, &timeout_todo);
d182 2
a183 2
		c->c_flags |= CALLOUT_PENDING;
		CIRCQ_INSERT(&c->c_list, &timeout_todo);
d186 1
a186 1
	CALLOUT_UNLOCK(s);
a188 5
/*
 * callout_stop:
 *
 *	Cancel a pending callout.
 */
d190 1
a190 1
callout_stop(struct callout *c)
d194 7
a200 8
	CALLOUT_LOCK(s);

	if (callout_pending(c))
		CIRCQ_REMOVE(&c->c_list);

	c->c_flags &= ~(CALLOUT_PENDING|CALLOUT_FIRED);

	CALLOUT_UNLOCK(s);
d206 2
d210 1
a210 1
callout_hardclock(void)
d212 7
a218 12
	int s;
	int needsoftclock;

	CALLOUT_LOCK(s);

	MOVEBUCKET(0, hardclock_ticks);
	if (MASKWHEEL(0, hardclock_ticks) == 0) {
		MOVEBUCKET(1, hardclock_ticks);
		if (MASKWHEEL(1, hardclock_ticks) == 0) {
			MOVEBUCKET(2, hardclock_ticks);
			if (MASKWHEEL(2, hardclock_ticks) == 0)
				MOVEBUCKET(3, hardclock_ticks);
d221 1
a221 5

	needsoftclock = !CIRCQ_EMPTY(&timeout_todo);
	CALLOUT_UNLOCK(s);

	return needsoftclock;
a223 1
/* ARGSUSED */
d225 1
a225 1
softclock(void *v)
d227 3
a229 2
	struct callout *c;
	void (*func)(void *);
a230 1
	int s;
d232 2
a233 1
	CALLOUT_LOCK(s);
d235 2
a236 3
	while (!CIRCQ_EMPTY(&timeout_todo)) {
		c = CIRCQ_FIRST(&timeout_todo);
		CIRCQ_REMOVE(&c->c_list);
d239 3
a241 3
		if (c->c_time - hardclock_ticks > 0) {
			CIRCQ_INSERT(&c->c_list,
			    BUCKET((c->c_time - hardclock_ticks), c->c_time));
d243 4
a246 3
#ifdef CALLOUT_EVENT_COUNTERS
			if (c->c_time - hardclock_ticks < 0)
				callout_ev_late.ev_count++;
d248 2
a249 2
			c->c_flags = (c->c_flags  & ~CALLOUT_PENDING) |
			    (CALLOUT_FIRED|CALLOUT_INVOKING);
d251 2
a252 2
			func = c->c_func;
			arg = c->c_arg;
d254 3
a256 3
			CALLOUT_UNLOCK(s);
			(*func)(arg);
			CALLOUT_LOCK(s);
d259 1
a259 2

	CALLOUT_UNLOCK(s);
d263 4
a266 2
static void
db_show_callout_bucket(struct callout_circq *bucket)
d268 2
a269 1
	struct callout *c;
d273 3
a275 6
	if (CIRCQ_EMPTY(bucket))
		return;

	for (c = CIRCQ_FIRST(bucket); /*nothing*/; c = CIRCQ_NEXT(&c->c_list)) {
		db_find_sym_and_offset((db_addr_t)(intptr_t)c->c_func, &name,
		    &offset);
d277 3
a279 12
#ifdef _LP64
#define	POINTER_WIDTH	"%16lx"
#else
#define	POINTER_WIDTH	"%8lx"
#endif
		db_printf("%9d %2d/%-4d " POINTER_WIDTH "  %s\n",
		    c->c_time - hardclock_ticks,
		    (int)((bucket - timeout_wheel) / WHEELSIZE),
		    (int)(bucket - timeout_wheel), (u_long) c->c_arg, name);

		if (CIRCQ_LAST(&c->c_list, bucket))
			break;
d286 1
d289 1
a289 4
	db_printf("hardclock_ticks now: %d\n", hardclock_ticks);
#ifdef _LP64
	db_printf("    ticks  wheel               arg  func\n");
#else
a290 1
#endif
d292 1
a292 5
	/*
	 * Don't lock the callwheel; all the other CPUs are paused
	 * anyhow, and we might be called in a circumstance where
	 * some other CPU was paused while holding the lock.
	 */
d297 2
d300 1
a300 1
#endif /* DDB */
@


1.1.1.1
log
@Import base OpenBSD repository of MirOS ocvs:HEAD
@
text
@@
